#!/usr/bin/env python3
"""
Generated by DNNE Queue-Based Export System
Metadata: {
  "name": "Simple MNIST Display Test"
}
"""

# Imports

# Configure logging
from abc import ABC, abstractmethod
from asyncio import Queue
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from typing import Dict, Any, List, Optional
import asyncio
import logging
import time
import torch
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(message)s')

# ==============================================================================
# Queue Framework
# ==============================================================================
# Queue-Based Node Framework
class QueueNode(ABC):
    """Base class for all queue-based nodes"""
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.input_queues: Dict[str, Queue] = {}
        self.output_subscribers: Dict[str, List[Queue]] = {}
        self.required_inputs: List[str] = []
        self.output_names: List[str] = []
        self.running = False
        self.compute_count = 0
        self.last_compute_time = 0.0
        self.logger = logging.getLogger(f"Node.{node_id}")
    
    def setup_inputs(self, required: List[str], queue_size: int = 100):
        """Setup input queues"""
        self.required_inputs = required
        for input_name in required:
            self.input_queues[input_name] = Queue(maxsize=queue_size)
    
    def setup_outputs(self, outputs: List[str]):
        """Setup output specifications"""
        self.output_names = outputs
        for output_name in outputs:
            self.output_subscribers[output_name] = []
    
    async def send_output(self, output_name: str, value: Any):
        """Send output to all subscribers"""
        if output_name in self.output_subscribers:
            for queue in self.output_subscribers[output_name]:
                await queue.put(value)
    
    @abstractmethod
    async def compute(self, **inputs) -> Dict[str, Any]:
        """Override this to implement node logic"""
        pass
    
    async def run(self):
        """Main execution loop"""
        self.running = True
        self.logger.info(f"Starting node {self.node_id}")
        
        try:
            while self.running:
                # Gather all required inputs
                inputs = {}
                for input_name in self.required_inputs:
                    value = await self.input_queues[input_name].get()
                    inputs[input_name] = value
                
                # Execute compute
                start_time = time.time()
                outputs = await self.compute(**inputs)
                self.last_compute_time = time.time() - start_time
                self.compute_count += 1
                
                # Send outputs
                for output_name, value in outputs.items():
                    await self.send_output(output_name, value)
                    
        except asyncio.CancelledError:
            self.logger.info(f"Node {self.node_id} cancelled")
            raise
        finally:
            self.running = False


class SensorNode(QueueNode):
    """Base class for sensor nodes that generate data at fixed rates"""
    
    def __init__(self, node_id: str, update_rate: float):
        super().__init__(node_id)
        self.update_rate = update_rate
        self.update_interval = 1.0 / update_rate
    
    async def run(self):
        """Sensor run loop with fixed rate"""
        self.running = True
        self.logger.info(f"Starting sensor {self.node_id} at {self.update_rate}Hz")
        
        try:
            while self.running:
                start_time = time.time()
                
                # Execute compute
                outputs = await self.compute()
                self.compute_count += 1
                
                # Send outputs
                for output_name, value in outputs.items():
                    await self.send_output(output_name, value)
                
                # Sleep to maintain rate
                elapsed = time.time() - start_time
                sleep_time = max(0, self.update_interval - elapsed)
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                    
                self.last_compute_time = time.time() - start_time
                
        except asyncio.CancelledError:
            self.logger.info(f"Sensor {self.node_id} cancelled")
            raise
        finally:
            self.running = False


class GraphRunner:
    """Manages and runs the complete node graph"""
    
    def __init__(self):
        self.nodes: Dict[str, QueueNode] = {}
        self.tasks: List[asyncio.Task] = []
        self.logger = logging.getLogger("GraphRunner")
    
    def add_node(self, node: QueueNode):
        """Add a node to the graph"""
        self.nodes[node.node_id] = node
        self.logger.info(f"Added node: {node.node_id}")
    
    def wire_nodes(self, connections: List[tuple]):
        """Wire nodes together: (from_id, output, to_id, input)"""
        for from_id, output_name, to_id, input_name in connections:
            from_node = self.nodes[from_id]
            to_node = self.nodes[to_id]
            
            # Subscribe to_node's input queue to from_node's output
            from_node.output_subscribers[output_name].append(
                to_node.input_queues[input_name]
            )
            self.logger.info(f"Connected {from_id}.{output_name} -> {to_id}.{input_name}")
    
    async def run(self, duration: Optional[float] = None):
        """Run all nodes"""
        self.logger.info("Starting graph execution")
        
        # Start all nodes
        for node in self.nodes.values():
            task = asyncio.create_task(node.run())
            self.tasks.append(task)
        
        try:
            if duration:
                await asyncio.sleep(duration)
                self.logger.info(f"Stopping after {duration}s")
            else:
                # Run until cancelled
                await asyncio.gather(*self.tasks)
        except KeyboardInterrupt:
            self.logger.info("Interrupted by user")
        finally:
            # Cancel all tasks
            for task in self.tasks:
                task.cancel()
            
            # Wait for cancellation
            await asyncio.gather(*self.tasks, return_exceptions=True)
            self.logger.info("All nodes stopped")
    
    def get_stats(self) -> Dict[str, Dict[str, Any]]:
        """Get execution statistics"""
        return {
            node_id: {
                "compute_count": node.compute_count,
                "last_compute_time": node.last_compute_time,
                "running": node.running
            }
            for node_id, node in self.nodes.items()
        }


# ==============================================================================
# Node Implementations
# ==============================================================================
# Template variables - replaced during export

class MNISTDatasetNode_data(SensorNode):
    """MNIST dataset loader that emits batches at fixed rate"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id, update_rate=2.0)
        self.setup_outputs(["batch_data", "batch_labels"])
        
        # Setup dataset
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        self.dataset = datasets.MNIST(
            root="./data",
            train=True,
            download=True,
            transform=transform
        )
        
        self.dataloader = DataLoader(
            self.dataset,
            batch_size=32,
            shuffle=True,
            num_workers=0
        )
        
        self.data_iter = iter(self.dataloader)
        self.epoch = 0
    
    async def compute(self) -> Dict[str, Any]:
        try:
            images, labels = next(self.data_iter)
        except StopIteration:
            # Reset iterator at end of epoch
            self.epoch += 1
            self.data_iter = iter(self.dataloader)
            images, labels = next(self.data_iter)
            self.logger.info(f"Starting epoch {self.epoch}")
        
        return {
            "batch_data": images,
            "batch_labels": labels
        }


# Template variables - replaced during export

class DisplayNode_display(QueueNode):
    """Display/logging node"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id)
        self.setup_inputs(required=["input_0"])
        self.setup_outputs([])  # No outputs
        
        self.display_type = "tensor_stats"
        self.display_count = 0
        self.log_interval = 1
    
    async def compute(self, input_0) -> Dict[str, Any]:
        self.display_count += 1
        
        # Only log at intervals
        if self.display_count % self.log_interval == 0:
            if self.display_type == "tensor_stats" and hasattr(input_0, 'shape'):
                self.logger.info(f"[{self.display_count}] Tensor shape: {input_0.shape}, "
                              f"min: {input_0.min().item():.4f}, "
                              f"max: {input_0.max().item():.4f}, "
                              f"mean: {input_0.mean().item():.4f}")
            elif self.display_type == "value":
                self.logger.info(f"[{self.display_count}] Value: {input_0}")
            else:
                self.logger.info(f"[{self.display_count}] {type(input_0)}")
        
        return {}  # No outputs


# ==============================================================================
# Main Execution
# ==============================================================================

async def main():
    """Main execution function"""
    print("ðŸš€ Starting DNNE Queue-Based Execution")
    print("=" * 60)

    # Create nodes
    data_node = MNISTDatasetNode_data("data")
    display_node = DisplayNode_display("display")

    # Create runner
    runner = GraphRunner()

    # Add nodes to runner
    runner.add_node(data_node)
    runner.add_node(display_node)

    # Wire connections
    connections = [
        ("data", "batch_data", "display", "input_0"),
    ]
    runner.wire_nodes(connections)

    # Run the graph
    try:
        # Run indefinitely (Ctrl+C to stop)
        # await runner.run()
        # Or run for specific duration:
        await runner.run(duration=10.0)  # Run for 10 seconds
    except KeyboardInterrupt:
        print('\nðŸ›‘ Stopped by user')

    # Show final statistics
    print('\nðŸ“Š Final Statistics:')
    stats = runner.get_stats()
    for node_id, node_stats in stats.items():
        print(f'  {node_id}: {node_stats["compute_count"]} computations, '
              f'avg time: {node_stats["last_compute_time"]:.3f}s')


if __name__ == '__main__':
    asyncio.run(main())