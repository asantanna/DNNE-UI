#!/usr/bin/env python3
"""
Generated by DNNE Queue-Based Export System
Metadata: {
  "export_time": "2025-06-26 04:06:01",
  "workflow_id": "0",
  "workflow_name": "workflow_20250626_040601"
}
"""

# Imports

# Configure logging
from abc import ABC, abstractmethod
from asyncio import Queue
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from typing import Dict, Any, List, Optional
import asyncio
import logging
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(message)s')

# ==============================================================================
# Queue Framework
# ==============================================================================
# Queue-Based Node Framework
class QueueNode(ABC):
    """Base class for all queue-based nodes"""
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.input_queues: Dict[str, Queue] = {}
        self.output_subscribers: Dict[str, List[Queue]] = {}
        self.required_inputs: List[str] = []
        self.output_names: List[str] = []
        self.running = False
        self.compute_count = 0
        self.last_compute_time = 0.0
        self.logger = logging.getLogger(f"Node.{node_id}")
    
    def setup_inputs(self, required: List[str], queue_size: int = 100):
        """Setup input queues"""
        self.required_inputs = required
        for input_name in required:
            self.input_queues[input_name] = Queue(maxsize=queue_size)
    
    def setup_outputs(self, outputs: List[str]):
        """Setup output specifications"""
        self.output_names = outputs
        for output_name in outputs:
            self.output_subscribers[output_name] = []
    
    async def send_output(self, output_name: str, value: Any):
        """Send output to all subscribers"""
        if output_name in self.output_subscribers:
            for queue in self.output_subscribers[output_name]:
                await queue.put(value)
    
    @abstractmethod
    async def compute(self, **inputs) -> Dict[str, Any]:
        """Override this to implement node logic"""
        pass
    
    async def run(self):
        """Main execution loop"""
        self.running = True
        self.logger.info(f"Starting node {self.node_id}")
        
        try:
            while self.running:
                # Gather all required inputs
                inputs = {}
                for input_name in self.required_inputs:
                    value = await self.input_queues[input_name].get()
                    inputs[input_name] = value
                
                # Execute compute
                start_time = time.time()
                outputs = await self.compute(**inputs)
                self.last_compute_time = time.time() - start_time
                self.compute_count += 1
                
                # Send outputs
                for output_name, value in outputs.items():
                    await self.send_output(output_name, value)
                    
        except asyncio.CancelledError:
            self.logger.info(f"Node {self.node_id} cancelled")
            raise
        finally:
            self.running = False


class SensorNode(QueueNode):
    """Base class for sensor nodes that generate data at fixed rates"""
    
    def __init__(self, node_id: str, update_rate: float):
        super().__init__(node_id)
        self.update_rate = update_rate
        self.update_interval = 1.0 / update_rate
    
    async def run(self):
        """Sensor run loop with fixed rate"""
        self.running = True
        self.logger.info(f"Starting sensor {self.node_id} at {self.update_rate}Hz")
        
        try:
            while self.running:
                start_time = time.time()
                
                # Execute compute
                outputs = await self.compute()
                self.compute_count += 1
                
                # Send outputs
                for output_name, value in outputs.items():
                    await self.send_output(output_name, value)
                
                # Sleep to maintain rate
                elapsed = time.time() - start_time
                sleep_time = max(0, self.update_interval - elapsed)
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                    
                self.last_compute_time = time.time() - start_time
                
        except asyncio.CancelledError:
            self.logger.info(f"Sensor {self.node_id} cancelled")
            raise
        finally:
            self.running = False


class GraphRunner:
    """Manages and runs the complete node graph"""
    
    def __init__(self):
        self.nodes: Dict[str, QueueNode] = {}
        self.tasks: List[asyncio.Task] = []
        self.logger = logging.getLogger("GraphRunner")
    
    def add_node(self, node: QueueNode):
        """Add a node to the graph"""
        self.nodes[node.node_id] = node
        self.logger.info(f"Added node: {node.node_id}")
    
    def wire_nodes(self, connections: List[tuple]):
        """Wire nodes together: (from_id, output, to_id, input)"""
        for from_id, output_name, to_id, input_name in connections:
            from_node = self.nodes[from_id]
            to_node = self.nodes[to_id]
            
            # Subscribe to_node's input queue to from_node's output
            from_node.output_subscribers[output_name].append(
                to_node.input_queues[input_name]
            )
            self.logger.info(f"Connected {from_id}.{output_name} -> {to_id}.{input_name}")
    
    async def run(self, duration: Optional[float] = None):
        """Run all nodes"""
        self.logger.info("Starting graph execution")
        
        # Start all nodes
        for node in self.nodes.values():
            task = asyncio.create_task(node.run())
            self.tasks.append(task)
        
        try:
            if duration:
                await asyncio.sleep(duration)
                self.logger.info(f"Stopping after {duration}s")
            else:
                # Run until cancelled
                await asyncio.gather(*self.tasks)
        except KeyboardInterrupt:
            self.logger.info("Interrupted by user")
        finally:
            # Cancel all tasks
            for task in self.tasks:
                task.cancel()
            
            # Wait for cancellation
            await asyncio.gather(*self.tasks, return_exceptions=True)
            self.logger.info("All nodes stopped")
    
    def get_stats(self) -> Dict[str, Dict[str, Any]]:
        """Get execution statistics"""
        return {
            node_id: {
                "compute_count": node.compute_count,
                "last_compute_time": node.last_compute_time,
                "running": node.running
            }
            for node_id, node in self.nodes.items()
        }


# ==============================================================================
# Node Implementations
# ==============================================================================
# Template variables - replaced during export

class LinearLayerNode_10(QueueNode):
    """Linear layer with activation"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id)
        self.setup_inputs(required=["input_tensor"])
        self.setup_outputs(["output_tensor"])
        
        # Create layer
        self.linear = nn.Linear(784, 128, bias=relu)
        self.dropout = nn.Dropout(0) if 0 > 0 else None
        self.activation = "True"
        
        # Move to GPU if available
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.linear = self.linear.to(self.device)
        
    async def compute(self, input_tensor) -> Dict[str, Any]:
        # Ensure input is on correct device
        x = input_tensor.to(self.device)
        
        # Flatten if needed (for MNIST)
        if x.dim() > 2:
            x = x.view(x.size(0), -1)
        
        # Forward pass
        x = self.linear(x)
        
        # Activation
        if self.activation == "relu":
            x = F.relu(x)
        elif self.activation == "tanh":
            x = torch.tanh(x)
        elif self.activation == "sigmoid":
            x = torch.sigmoid(x)
        
        # Dropout if training
        if self.dropout is not None:
            x = self.dropout(x)
        
        return {"output_tensor": x}


# Template variables - replaced during export

class LossNode_11(QueueNode):
    """Loss computation node"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id)
        self.setup_inputs(required=["predictions", "labels"])
        self.setup_outputs(["loss", "accuracy"])
        
        # Setup loss function
        self.loss_type = "cross_entropy"
        if self.loss_type == "cross_entropy":
            self.criterion = nn.CrossEntropyLoss()
        elif self.loss_type == "mse":
            self.criterion = nn.MSELoss()
        else:
            self.criterion = nn.L1Loss()
    
    async def compute(self, predictions, labels) -> Dict[str, Any]:
        # Compute loss
        loss = self.criterion(predictions, labels)
        
        # Compute accuracy for classification
        accuracy = 0.0
        if self.loss_type == "cross_entropy":
            _, predicted = torch.max(predictions, 1)
            correct = (predicted == labels).sum().item()
            total = labels.size(0)
            accuracy = correct / total if total > 0 else 0.0
        
        self.logger.info(f"Loss: {loss.item():.4f}, Accuracy: {accuracy:.2%}")
        
        return {
            "loss": loss,
            "accuracy": accuracy
        }


# Template variables - replaced during export

class MNISTDatasetNode_13(SensorNode):
    """MNIST dataset loader that emits batches at fixed rate"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id, update_rate=10.0)
        self.setup_outputs(["batch_data", "batch_labels"])
        
        # Setup dataset
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        self.dataset = datasets.MNIST(
            root="./data",
            train=True,
            download=True,
            transform=transform
        )
        
        self.dataloader = DataLoader(
            self.dataset,
            batch_size=32,
            shuffle=True,
            num_workers=0
        )
        
        self.data_iter = iter(self.dataloader)
        self.epoch = 0
    
    async def compute(self) -> Dict[str, Any]:
        try:
            images, labels = next(self.data_iter)
        except StopIteration:
            # Reset iterator at end of epoch
            self.epoch += 1
            self.data_iter = iter(self.dataloader)
            images, labels = next(self.data_iter)
            self.logger.info(f"Starting epoch {self.epoch}")
        
        return {
            "batch_data": images,
            "batch_labels": labels
        }


# Template variables - replaced during export

class MNISTDatasetNode_14(SensorNode):
    """MNIST dataset loader that emits batches at fixed rate"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id, update_rate=10.0)
        self.setup_outputs(["batch_data", "batch_labels"])
        
        # Setup dataset
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        self.dataset = datasets.MNIST(
            root="./data",
            train=True,
            download=True,
            transform=transform
        )
        
        self.dataloader = DataLoader(
            self.dataset,
            batch_size=32,
            shuffle=True,
            num_workers=0
        )
        
        self.data_iter = iter(self.dataloader)
        self.epoch = 0
    
    async def compute(self) -> Dict[str, Any]:
        try:
            images, labels = next(self.data_iter)
        except StopIteration:
            # Reset iterator at end of epoch
            self.epoch += 1
            self.data_iter = iter(self.dataloader)
            images, labels = next(self.data_iter)
            self.logger.info(f"Starting epoch {self.epoch}")
        
        return {
            "batch_data": images,
            "batch_labels": labels
        }


# Template variables - replaced during export

# Extract variables
NODE_ID = template_vars["NODE_ID"]
DATALOADER_VAR = template_vars["DATALOADER_VAR"]
# Get Batch configuration
# This node represents getting batches in the training loop
globals()[f"node_15_config"] = {
    "dataloader_var": DATALOADER_VAR,
    "outputs": ["batch_images", "batch_labels"]
}

print(f"Configured batch getter 'node_15' from dataloader 'dataloader'")

# Template variables - replaced during export

class LinearLayerNode_16(QueueNode):
    """Linear layer with activation"""
    
    def __init__(self, node_id: str):
        super().__init__(node_id)
        self.setup_inputs(required=["input_tensor"])
        self.setup_outputs(["output_tensor"])
        
        # Create layer
        self.linear = nn.Linear(784, 128, bias=none)
        self.dropout = nn.Dropout(0) if 0 > 0 else None
        self.activation = "True"
        
        # Move to GPU if available
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.linear = self.linear.to(self.device)
        
    async def compute(self, input_tensor) -> Dict[str, Any]:
        # Ensure input is on correct device
        x = input_tensor.to(self.device)
        
        # Flatten if needed (for MNIST)
        if x.dim() > 2:
            x = x.view(x.size(0), -1)
        
        # Forward pass
        x = self.linear(x)
        
        # Activation
        if self.activation == "relu":
            x = F.relu(x)
        elif self.activation == "tanh":
            x = torch.tanh(x)
        elif self.activation == "sigmoid":
            x = torch.sigmoid(x)
        
        # Dropout if training
        if self.dropout is not None:
            x = self.dropout(x)
        
        return {"output_tensor": x}


# Template variables - replaced during export

# Extract variables
NODE_ID = template_vars["NODE_ID"]
LEARNING_RATE = template_vars["LEARNING_RATE"]
MOMENTUM = template_vars["MOMENTUM"]
WEIGHT_DECAY = template_vars["WEIGHT_DECAY"]

# SGD Optimizer configuration
globals()[f"node_20_config"] = {
    "type": "SGD",
    "lr": LEARNING_RATE,
    "momentum": MOMENTUM,
    "weight_decay": WEIGHT_DECAY
}

print(f"Configured SGD optimizer 'node_20': lr=0.01, momentum=0.9")

# Template variables - replaced during export

# Extract variables
NODE_ID = template_vars["NODE_ID"]
LOSS_VAR = template_vars["LOSS_VAR"]
OPTIMIZER_VAR = template_vars["OPTIMIZER_VAR"]

# Training step configuration
globals()[f"node_21_config"] = {
    "type": "TrainingStep",
    "loss_var": LOSS_VAR,
    "optimizer_var": OPTIMIZER_VAR
}

print(f"Configured training step 'node_21'")

# ==============================================================================
# Main Execution
# ==============================================================================

async def main():
    """Main execution function"""
    print("ðŸš€ Starting DNNE Queue-Based Execution")
    print("=" * 60)

    # Create nodes
    10_node = LinearLayerNode_10("10")
    11_node = LossNode_11("11")
    13_node = MNISTDatasetNode_13("13")
    14_node = MNISTDatasetNode_14("14")
    15_node = GetBatchNode_15("15")
    16_node = LinearLayerNode_16("16")
    20_node = SGDOptimizerNode_20("20")
    21_node = TrainingStepNode_21("21")

    # Create runner
    runner = GraphRunner()

    # Add nodes to runner
    runner.add_node(10_node)
    runner.add_node(11_node)
    runner.add_node(13_node)
    runner.add_node(14_node)
    runner.add_node(15_node)
    runner.add_node(16_node)
    runner.add_node(20_node)
    runner.add_node(21_node)

    # Wire connections
    connections = [
        ("15", "output_0", "10", "input_tensor"),
        ("16", "output_tensor", "11", "input_0"),
        ("15", "output_1", "11", "input_0"),
        ("13", "batch_data", "14", "input_0"),
        ("14", "output_0", "15", "input_0"),
        ("10", "output_tensor", "16", "input_tensor"),
        ("11", "output_0", "21", "input_0"),
        ("20", "output_0", "21", "input_0"),
    ]
    runner.wire_nodes(connections)

    # Run the graph
    try:
        # Run indefinitely (Ctrl+C to stop)
        await runner.run()
        # Or run for specific duration:
        # await runner.run(duration=10.0)  # Run for 10 seconds
    except KeyboardInterrupt:
        print('\nðŸ›‘ Stopped by user')

    # Show final statistics
    print('\nðŸ“Š Final Statistics:')
    stats = runner.get_stats()
    for node_id, node_stats in stats.items():
        print(f'  {node_id}: {node_stats["compute_count"]} computations, '
              f'avg time: {node_stats["last_compute_time"]:.3f}s')


if __name__ == '__main__':
    asyncio.run(main())